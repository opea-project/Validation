# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

name: Run accuary test on a Gaudi

on:
  workflow_dispatch:
    inputs:
      examples:
        default: "ChatQnA"
        description: 'List of examples to test [AudioQnA,ChatQnA,CodeGen,FaqGen]'
        required: true
        type: string
      datasets:
        default: "en"
        description: "List of services to test [en, zh]"
        required: true
        type: string

  pull_request:
    branches: [main]
    types: [opened, reopened, ready_for_review, synchronize]

# If there is a new commit, the previous jobs will be canceled
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  get-test-matrix:
    runs-on: ubuntu-latest
    outputs:
      datasets: ${{ steps.get-matrix.outputs.datasets }}
      examples: ${{ steps.get-matrix.outputs.examples }}
    steps:
      - name: Create Matrix
        id: get-matrix
        run: |
          # datasets=($(echo ${{ inputs.datasets }} | tr ',' ' '))
          datasets=($(echo "en" | tr ',' ' '))
          datasets_json=$(printf '%s\n' "${datasets[@]}" | jq -R '.' | jq -sc '.')
          echo "datasets=$datasets_json" >> $GITHUB_OUTPUT
          examples=($(echo "ChatQnA,CodeGen,FaqGen" | tr ',' ' '))  
          examples_json=$(printf '%s\n' "${examples[@]}" | jq -R '.' | jq -sc '.')
          echo "examples=$examples_json" >> $GITHUB_OUTPUT

  setup-acc:
    runs-on: aise-acc
    needs: [get-test-matrix]
    strategy:
      matrix:
        dataset: ${{ fromJson(needs.get-test-matrix.outputs.datasets) }}
        example: ${{ fromJson(needs.get-test-matrix.outputs.examples) }}
        exclude:
          - example: [AudioQnA, CodeGen, FaqGen]
            dataset: zh
      fail-fast: false
    steps:
      - name: Clean up Working Directory
        run: |
          sudo rm -rf ${{github.workspace}}/* || true
          docker system prune -f
          docker rmi $(docker images --filter reference="*/*:acc" -q) || true

      - name: Checkout out Validation
        uses: actions/checkout@v4
        with:
          path: Validation

      - name: Checkout out GenAIEval
        uses: actions/checkout@v4
        with:
          repository: opea-project/GenAIEval
          path: GenAIEval

      - name: Checkout out GenAIExamples
        uses: actions/checkout@v4
        with:
          repository: opea-project/GenAIExamples
          path: GenAIExamples

      - name: Set up environment
        env:
          example: ${{ matrix.example }}
        run: |
          set -x
          echo "Dataset: ${{ matrix.dataset }}"
          echo "Example: ${{ matrix.example }}"
          cd ${{ github.workspace }}/GenAIEval
          pip install -r requirements.txt
          if [[ "${example}" == "AudioQnA" ]]; then
            cd ${{ github.workspace }}/GenAIExamples/AudioQnA/benchmark/accuracy
            pip install -r requirements.txt
          elif [[ "${example}" == "CodeGen" ]]; then
            pip install -e .
          fi

      - name: Launch Service
        env:
          HUGGINGFACEHUB_API_TOKEN: ${{ secrets.HUGGINGFACEHUB_API_TOKEN }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          example: ${{ matrix.example }}
          dataset: ${{ matrix.dataset }}
          port: 9001
          IMAGE_TAG: acc
        run: |
          ip_address=$(hostname -I | awk '{print $1}')
          cd ${{ github.workspace }}/GenAIExamples/${example}/tests/
          cp ${{ github.workspace }}/Validation/.github/scripts/launch_service/launch_"${example}"*.sh .          
          if [[ "${example}" == "ChatQnA" ]]; then
            bash launch_"${example}"_"${dataset}".sh
            if [[ "${dataset}" == "en" ]]; then
              cd ${{ github.workspace }}/GenAIEval/
              DPATH=$(dirname "$PWD")
              export PYTHONPATH=$PYTHONPATH:$DPATH
              export PATH=$PATH:/bin:/usr/bin
              cd ${{ github.workspace }}/GenAIEval/evals/evaluation/rag_eval/examples
              # docker run -tid -p ${port}:80 --runtime=habana -e HABANA_VISIBLE_DEVICES=1,2 -e HABANA_VISIBLE_MODULES=6,7 -e
              docker run -tid -p ${port}:80 --runtime=habana -e HABANA_VISIBLE_DEVICES=all -e PT_HPU_ENABLE_LAZY_COLLECTIVES=true -e OMPI_MCA_btl_vader_single_copy_mechanism=none -e HF_TOKEN=${HF_TOKEN} --cap-add=sys_nice --ipc=host ghcr.io/huggingface/tgi-gaudi:2.0.1 --model-id mistralai/Mixtral-8x7B-Instruct-v0.1 --max-input-tokens 2048 --max-total-tokens 4096 --sharded true --num-shard 2
            else
              echo "ChatQnA dataset is ${dataset}."
            fi
          elif [[ "${example}" == "FaQGen" ]]; then
            bash launch_"${example}".sh
            export FAQ_ENDPOINT = "http://${your_ip}:9000/v1/faqgen"
            cd ${{ github.workspace }}/GenAIExamples/${example}/benchmark/accuracy
            sed -i 's/f = open("data\/sqv2_context.json", "r")/f = open("\/data2\/opea-dataset\/FaqGen\/sqv2_context.json", "r")/g' generate_FAQ.py
            # sed -i 's/with open("data\/sqv2_faq.json", "w") as outfile:/with open("\/data2\/opea-dataset\/FaqGen\/sqv2_faq.json", "w") as outfile:/g' post_process_FAQ.py
            sed -i 's/f = open("data\/sqv2_context.json", "r")/f = open("\/data2\/opea-dataset\/FaqGen\/sqv2_context.json", "r")/g' evaluate.py
            # sed -i 's/with open("data\/sqv2_faq.json", "w") as outfile:/with open("\/data2\/opea-dataset\/FaqGen\/sqv2_faq.json", "w") as outfile:/g' evaluate.py
            python generate_FAQ.py
            python post_process_FAQ.py

            export HUGGING_FACE_HUB_TOKEN="${HUGGINGFACEHUB_API_TOKEN}"
            bash launch_tgi.sh
          else
            bash launch_"${example}".sh
            echo "${example}"
          fi

      # - name: Launch Service of LLM-as-a-Judge
      #   shell: bash
      #   if: ${{ matrix.dataset }} == 'en' && ${{ matrix.dataset }} == 'ChatQnA'
      #   env:
      #     HUGGINGFACEHUB_API_TOKEN: ${{ secrets.HUGGINGFACEHUB_API_TOKEN }}
      #     HF_TOKEN: ${{ secrets.HF_TOKEN }}
      #     dataset: ${{ matrix.dataset }}
      #     port: 9001
      #   run: |
      #     cd ${{ github.workspace }}/GenAIEval/
      #     DPATH=$(dirname "$PWD")
      #     export PYTHONPATH=$PYTHONPATH:$DPATH
      #     export PATH=$PATH:/bin:/usr/bin
      #     cd ${{ github.workspace }}/GenAIEval/evals/evaluation/rag_eval/examples
      #     # docker run -tid -p ${port}:80 --runtime=habana -e HABANA_VISIBLE_DEVICES=1,2 -e HABANA_VISIBLE_MODULES=6,7 -e
      #     docker run -tid -p ${port}:80 --runtime=habana -e HABANA_VISIBLE_DEVICES=all -e PT_HPU_ENABLE_LAZY_COLLECTIVES=true -e OMPI_MCA_btl_vader_single_copy_mechanism=none -e HF_TOKEN=${HF_TOKEN} --cap-add=sys_nice --ipc=host ghcr.io/huggingface/tgi-gaudi:2.0.1 --model-id mistralai/Mixtral-8x7B-Instruct-v0.1 --max-input-tokens 2048 --max-total-tokens 4096 --sharded true --num-shard 2

      - name: Run Evaluation
        env:
          HUGGINGFACEHUB_API_TOKEN: ${{ secrets.HUGGINGFACEHUB_API_TOKEN }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          example: ${{ matrix.example }}
          dataset: ${{ matrix.dataset }}
          port: 9001
        run: |
          ip_address=$(hostname -I | awk '{print $1}')
          mkdir acc-log
          cd ${{ github.workspace }}/GenAIExamples/${example}/benchmark/accuracy
          if [[ "${example}" == "CodeGen " ]]; then
            export CODEGEN_ENDPOINT="http://${your_ip}:7778/v1/codegen"
            export CODEGEN_MODEL="Qwen/CodeQwen1.5-7B-Chat"
            bash run_acc.sh $CODEGEN_MODEL $CODEGEN_ENDPOINT > ${{ github.workspace }}/acc-log/${example}.txt
          elif [[ "${example}" == "ChatQnA" ]]; then
            sed -i 's/--docs_path MultiHop-RAG\/dataset\/corpus.json/--docs_path \/data2\/opea-dataset\/${example}\/MultiHop-RAG\/dataset\/corpus.json/g' run_acc.sh
            sed -i 's/--dataset_path MultiHop-RAG\/dataset\/MultiHopRAG.json/--dataset_path \/data2\/opea-dataset\/${example}\/MultiHop-RAG\/dataset\/MultiHopRAG.json/g' run_acc.sh
            sed -i 's/--dataset_path \.\.\/data\/split_merged.json/--dataset_path \/data2\/opea-dataset\/${example}\/data\/split_merged.json/g' run_acc.sh
            sed -i 's/--docs_path \.\.\/data\/80000_docs/--docs_path \/data2\/opea-dataset\/${example}\/data\/80000_docs/g' run_acc.sh
            sed -i '/git clone https:\/\/github.com\/yixuantt\/MultiHop-RAG.git/d' run_acc.sh
            sed -i '/git clone https:\/\/github.com\/IAAR-Shanghai\/CRUD_RAG/d' \
                   '/mkdir data\//d' \
                   '/cp CRUD_RAG\/data\/crud_split\/split_merged.json data\//d' \
                   '/cp -r CRUD_RAG\/data\/80000_docs\/ data\//d' \
                   '/python process_crud_dataset.py/d' run_acc.sh
            bash run_acc.sh ${dataset} > ${{ github.workspace }}/acc-log/${example}-${dataset}.txt
          elif [[ "${example}" == "AudioQnA" ]]; then
            python online_eval.py > ${{ github.workspace }}/acc-log/${example}-${dataset}.txt
          fi
          bash run_acc.sh >  ${{ github.workspace }}/acc-log/${example}.txt
          # cd ${{ github.workspace }}/GenAIEval/
          # DPATH=$(pwd)
          # export PYTHONPATH=$PYTHONPATH:$DPATH
          # export PATH=$PATH:/bin:/usr/bin
          # cd ${{ github.workspace }}/GenAIEval/evals/evaluation/rag_eval/examples
          # if [[ "${dataset}" == "en" ]]; then
          #  # --ragas_metrics 
          #   python eval_multihop.py --docs_path /data2/opea-dataset/${{ matrix.example }}/MultiHop-RAG/dataset/corpus.json  --dataset_path /data2/opea-dataset/${{ matrix.example }}/MultiHop-RAG/dataset/MultiHopRAG.json --ingest_docs --chunk_size 512 --chunk_overlap 200 --retrieval_metrics --llm_endpoint http://${ip_address}:${port}/generate > en-without-rerank.txt

          #   python eval_multihop.py --docs_path /data2/opea-dataset/${{ matrix.example }}/MultiHop-RAG/dataset/corpus.json  --dataset_path /data2/opea-dataset/${{ matrix.example }}/MultiHop-RAG/dataset/MultiHopRAG.json --retrieval_metrics --rerank --retrival_k 20 --llm_endpoint http://${ip_address}:${port}/generate > en-with-rerank.txt

          # elif [[ "${dataset}" == "zh" ]]; then
          #   python eval_crud.py --dataset_path /data2/opea-dataset/${{ matrix.example }}/data/split_merged.json --docs_path /data2/opea-dataset/${{ matrix.example }}/data/80000_docs --ingest_docs > zh.txt
          # fi

      - name: Clean up container
        if: always()
        env: 
          example: ${{ matrix.example }}
        run: |
          docker system prune -f
          cd ${{ github.workspace }}/GenAIExamples/${example}/docker_compose/intel/hpu/gaudi
          docker compose stop && docker compose rm -f
          docker rmi $(docker images --filter reference="*/*:acc" -q) || true

      - name: Publish pipeline artifact
        if: ${{ !cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.example }}
          payh: ${{ github.workspace }}/acc-log/${example}*.txt
