# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

name: Run accuary test on a Gaudi

on:
  workflow_dispatch:
    inputs:
      # registry:
      #   default: ""
      #   description: "Registry to store images,e.g., docker.io, default is empty"
      #   required: false
      #   type: string
      # nodes:
      #   default: "gaudi"
      #   description: "Hardware to run test"
      #   required: true
      #   type: string
      datasets:
        default: "en"
        description: "List of services to test [en, zh]"
        required: true
        type: string
      # tag:
      #   default: "rc0.9"
      #   description: "Tag to apply to images"
      #   required: true
      #   type: string
      # opea_branch:
      #   default: "rc0.9"
      #   description: "Branch to build images"
      #   required: true
      #   type: string
      # runner:
      #   description: "Runner label"
      #   required: true
      #   type: string
  pull_request:
    branches: [main]
    types: [opened, reopened, ready_for_review, synchronize]

# If there is a new commit, the previous jobs will be canceled
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  get-test-matrix:
    runs-on: ubuntu-latest
    outputs:
      datasets: ${{ steps.get-matrix.outputs.datasets }}
    steps:
      - name: Create Matrix
        id: get-matrix
        run: |
          # datasets=($(echo ${{ inputs.datasets }} | tr ',' ' '))
          datasets=($(echo "en,zh" | tr ',' ' '))
          datasets_json=$(printf '%s\n' "${datasets[@]}" | jq -R '.' | jq -sc '.')
          echo "datasets=$datasets_json" >> $GITHUB_OUTPUT

  setup-acc:
    runs-on: aise-acc
    needs: [get-test-matrix]
    strategy:
      matrix:
        dataset: ${{ fromJson(needs.get-test-matrix.outputs.datasets) }}
      fail-fast: false
    steps:
      - name: Clean Up Working Directory
        run: sudo rm -rf ${{github.workspace}}/*

      - name: Checkout out Validation
        uses: actions/checkout@v4
        with:
          path: Validation

      - name: Checkout out GenAIEval
        uses: actions/checkout@v4
        with:
          repository: opea-project/GenAIEval
          path: GenAIEval

      - name: Checkout out GenAIExamples
        uses: actions/checkout@v4
        with:
          repository: opea-project/GenAIExamples
          path: GenAIExamples

      - name: Set up environment
        run: |
          cd GenAIEval
          pip install -r requirements.txt

      - name: Launch Service of RAG System
        env:
          dataset: ${{ matrix.dataset }}
          node: ${{ matrix.node }}
        run: |
          export IMAGE_TAG=acc
          cd ${{ github.workspace }}/GenAIExamples/ChatQnA/tests/
          if [[ "${dataset}" == "zh" ]]; then
            head -n "$(($(wc -l < test_compose_on_gaudi.sh) - 10))" "test_compose_on_gaudi.sh" > launch_rag_zh.sh
            echo "}" >> launch_rag_zh.sh
            echo "main" >> launch_rag_zh.sh
            sed -i 's/export EMBEDDING_MODEL_ID="BAAI\/bge-base-en-v1.5"/export EMBEDDING_MODEL_ID="BAAI\/bge-base-zh-v1.5"/' launch_rag_zh.sh
            sed -i 's/export LLM_MODEL_ID="Intel\/neural-chat-7b-v3-3"/export LLM_MODEL_ID="Qwen\/Qwen2-7B-Instruct"/' launch_rag_zh.sh
            cat launch_rag_zh.sh
            bash launch_rag_zh.sh
          else
            head -n "$(($(wc -l < test_compose_on_gaudi.sh) - 10))" "test_compose_on_gaudi.sh" > launch_rag_en.sh
            echo "}" >> launch_rag_en.sh
            echo "main" >> launch_rag_en.sh
            cat launch_rag_en.sh
            bash launch_rag_en.sh
          fi

      - name: Launch Service of LLM-as-a-Judge
        shell: bash
        if: ${{ matrix.dataset }} == 'en'
        env:
          HUGGINGFACEHUB_API_TOKEN: ${{ secrets.HUGGINGFACEHUB_API_TOKEN }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          dataset: ${{ matrix.dataset }}
          port: 9001
        run: |
          cd ${{ github.workspace }}/GenAIEval/
          DPATH=$(dirname "$PWD")
          export PYTHONPATH=$PYTHONPATH:$DPATH
          export PATH=$PATH:/bin:/usr/bin
          cd ${{ github.workspace }}/GenAIEval/evals/evaluation/rag_eval/examples
          # docker run -tid -p ${port}:80 --runtime=habana -e HABANA_VISIBLE_DEVICES=1,2 -e HABANA_VISIBLE_MODULES=6,7 -e
          docker run -tid -p ${port}:80 --runtime=habana -e HABANA_VISIBLE_DEVICES=all -e PT_HPU_ENABLE_LAZY_COLLECTIVES=true -e OMPI_MCA_btl_vader_single_copy_mechanism=none -e HF_TOKEN=${HF_TOKEN} --cap-add=sys_nice --ipc=host ghcr.io/huggingface/tgi-gaudi:2.0.1 --model-id mistralai/Mixtral-8x7B-Instruct-v0.1 --max-input-tokens 2048 --max-total-tokens 4096 --sharded true --num-shard 2

      - name: Run Evaluation
        env:
          HUGGINGFACEHUB_API_TOKEN: ${{ secrets.HUGGINGFACEHUB_API_TOKEN }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          dataset: ${{ matrix.dataset }}
          port: 9001
        run: |
          ip_address=$(hostname -I | awk '{print $1}')
          cd ${{ github.workspace }}/GenAIEval/
          DPATH=$(pwd)
          export PYTHONPATH=$PYTHONPATH:$DPATH
          export PATH=$PATH:/bin:/usr/bin
          cd ${{ github.workspace }}/GenAIEval/evals/evaluation/rag_eval/examples
          if [[ "${dataset}" == "en" ]]; then
           # --ragas_metrics 
            python eval_multihop.py --docs_path /data2/opea-dataset/MultiHop-RAG/dataset/corpus.json  --dataset_path /data2/opea-dataset/MultiHop-RAG/dataset/MultiHopRAG.json --ingest_docs --chunk_size 512 --chunk_overlap 200 --retrieval_metrics --llm_endpoint http://${ip_address}:${port}/generate > en-without-rerank.txt

            python eval_multihop.py --docs_path /data2/opea-dataset/MultiHop-RAG/dataset/corpus.json  --dataset_path /data2/opea-dataset/MultiHop-RAG/dataset/MultiHopRAG.json --retrieval_metrics --rerank --retrival_k 20 --llm_endpoint http://${ip_address}:${port}/generate > en-with-rerank.txt

          elif [[ "${dataset}" == "zh" ]]; then
            python eval_crud.py --dataset_path /data2/opea-dataset/data/split_merged.json --docs_path /data2/opea-dataset/data/80000_docs --ingest_docs > zh.txt
          fi

      - name: Clean up container
        if: always()
        run: |
          docker system prune -f
          docker rmi $(docker images --filter reference="*/*:acc" -q) || true

      # - name: Publish pipeline artifact
      #   if: ${{ !cancelled() }}
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: ${{ matrix.dataset }}
      #     path: ${{ github.workspace }}/acc/*.txt
